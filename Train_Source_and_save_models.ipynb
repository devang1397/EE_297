{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import keras\n",
    "import sklearn.metrics\n",
    "import math\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding3D, BatchNormalization, Flatten, Conv3D, AveragePooling3D, MaxPooling3D, GlobalMaxPooling3D\n",
    "from keras.models import Model\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from keras import regularizers\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pick_class(Class , Cube_size , Data, Gt, small_segmented_1, small_seg_gt_1, overlap_ratio, ch):\n",
    "    indx_class = np.where(Gt == Class)\n",
    "    all_indx = [[indx_class[0][i],indx_class[1][i]] for i in range(len(indx_class[0])) if len(Gt)-np.ceil(Cube_size/2)>indx_class[0][i]>np.ceil(Cube_size/2) and len(Gt[0])-np.ceil(Cube_size/2)>indx_class[1][i]>np.ceil(Cube_size/2)]\n",
    "    lst = []\n",
    "    small_segmented_1.append(np.array(Data[:ch, all_indx[0][0]-int(Cube_size/2):all_indx[0][0] + int(Cube_size/2), (all_indx[0][1]-int(Cube_size/2)):all_indx[0][1]+int(Cube_size/2)]))\n",
    "    small_seg_gt_1.append(Class)\n",
    "    lst.append([all_indx[0][0], all_indx[0][1]])\n",
    "    for i in range(1, len(all_indx)):\n",
    "        dist = []\n",
    "        for k in range(len(lst)):\n",
    "            d = math.sqrt((all_indx[i][0]-lst[k][0])**2 + (all_indx[i][1]-lst[k][1])**2)\n",
    "            dist.append(d)\n",
    "        if np.min(dist) > int(Cube_size*(1-overlap_ratio)):\n",
    "            small_segmented_1.append(np.array(Data[:ch, all_indx[i][0]-int(Cube_size/2):all_indx[i][0] + int(Cube_size/2), (all_indx[i][1]-int(Cube_size/2)):all_indx[i][1]+int(Cube_size/2)]))\n",
    "            small_seg_gt_1.append(Class)\n",
    "            lst.append([all_indx[i][0], all_indx[i][1]])\n",
    "    return small_segmented_1, small_seg_gt_1, lst\n",
    "\n",
    "def pick_n_class(range_of_class, Cube_size, Data, Gt, small_segmented_1, small_seg_gt_1, overlap_ratio, ch):\n",
    "    class_len = []\n",
    "    for i in range_of_class:\n",
    "        \n",
    "        small_segmented_1, small_seg_gt_1, lst = pick_class(i, Cube_size, Data, Gt, small_segmented_1, small_seg_gt_1, overlap_ratio, ch)\n",
    "        class_len.append(len(lst))\n",
    "    small_segmented_1 = np.array(small_segmented_1)\n",
    "    small_seg_gt_1 = np.array(small_seg_gt_1)\n",
    "    return small_segmented_1, small_seg_gt_1, class_len\n",
    "\n",
    "\n",
    "\n",
    "def train_test_split(percentage, class_len, Data, Gt):\n",
    "    Xtrain = []\n",
    "    Xtest = []\n",
    "    Ytrain = []\n",
    "    Ytest = []\n",
    "    class_division = [0]\n",
    "    c = 0\n",
    "    for i in range(len(class_len)):\n",
    "        class_division.append(int(class_len[i]*(percentage/100)) + c)\n",
    "        class_division.append(class_len[i]+c)\n",
    "        c = class_len[i]+c\n",
    "    for i in range(1, len(class_division)):\n",
    "        if i%2!=0:\n",
    "            for j in range(class_division[i-1], class_division[i]):\n",
    "                Xtrain.append(Data[j])\n",
    "                Ytrain.append(Gt[j])\n",
    "        else:\n",
    "            for k in range(class_division[i-1], class_division[i]):\n",
    "                Xtest.append(Data[k])\n",
    "                Ytest.append(Gt[k])    \n",
    "    Xtrain = np.array(Xtrain)\n",
    "    Xtest = np.array(Xtest)\n",
    "    Ytrain = np.array(Ytrain)\n",
    "    Ytest = np.array(Ytest)\n",
    "    s = np.arange(Xtrain.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    Xtrain = Xtrain[s]\n",
    "    Ytrain = Ytrain[s]\n",
    "    s = np.arange(Xtest.shape[0])\n",
    "    np.random.shuffle(s)\n",
    "    Xtest = Xtest[s]\n",
    "    Ytest = Ytest[s]\n",
    "    Xtrain = np.expand_dims(Xtrain,axis=4) \n",
    "    Xtest = np.expand_dims(Xtest,axis=4) \n",
    "    Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape\n",
    "    values,counts = np.unique(Ytest, return_counts=True)\n",
    "    print(\"Total samples per class: \" + str(class_len) + \", Total number of samples is \" + str(np.sum(class_len))+'.\\n')\n",
    "    print(\"unique classes in Ytest: \" + str(values) + \", Total number of samples in Ytest is \" + str(np.sum(counts))+'.\\n'\n",
    "          +\"number of samples per class in Ytest: \" + str(counts) + '\\n')\n",
    "    \n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    Ytrain = Ytrain.reshape(len(Ytrain), 1)\n",
    "    Ytest = Ytest.reshape(len(Ytest),1)\n",
    "    Ytrain = onehot_encoder.fit_transform(Ytrain)\n",
    "    Ytest = onehot_encoder.fit_transform(Ytest)\n",
    "    \n",
    "    return Xtrain, Xtest, Ytrain, Ytest, class_len, counts\n",
    "\n",
    "def prepare_data_for_training(range_of_class, Cube_size, Data , Gt, small_segmented_1, small_seg_gt_1, percentage, overlap_ratio, ch):\n",
    "    small_segmented_1, small_seg_gt_1, class_len = pick_n_class(range_of_class, Cube_size, Data, Gt, small_segmented_1, small_seg_gt_1, overlap_ratio, ch)\n",
    "    Xtrain, Xtest, Ytrain, Ytest, class_len, counts = train_test_split(percentage, class_len, small_segmented_1, small_seg_gt_1)\n",
    "    return Xtrain, Xtest, Ytrain, Ytest, class_len, counts\n",
    "\n",
    "def SR_Unit(X, filters):\n",
    "    # Save the input value\n",
    "    X_shortcut = X\n",
    "    l2_= 0.001\n",
    "    X = Conv3D(filters, (1, 1, 1), kernel_regularizer=regularizers.l2(l2_),padding = \"same\", name='SR_Unit_'+str(filters)+'_conv_1')(X)\n",
    "    X = BatchNormalization(axis = 4, name='SR_Unit_'+str(filters)+'_bn_1')(X)\n",
    "    X = Activation('relu', name='SR_Unit_'+str(filters)+'_activation_1')(X)\n",
    "\n",
    "    X = Conv3D(filters, kernel_size = (1, 3, 3), kernel_regularizer=regularizers.l2(l2_), padding = 'same', name='SR_Unit_'+str(filters)+'_conv_2')(X)\n",
    "    X = BatchNormalization(axis = 4, name='SR_Unit_'+str(filters)+'_bn_2')(X)\n",
    "    X = Activation('relu', name='SR_Unit_'+str(filters)+'_activation_2')(X)\n",
    "\n",
    "    X = Conv3D(filters, kernel_size = (3, 1, 1), kernel_regularizer=regularizers.l2(l2_), padding = \"same\", name='SR_Unit_'+str(filters)+'_conv_3')(X)\n",
    "    X = BatchNormalization(axis = 4, name='SR_Unit_'+str(filters)+'_bn_3')(X)\n",
    "    X = Activation('relu', name='SR_Unit_'+str(filters)+'_activation_3')(X)\n",
    "\n",
    "    X = Conv3D(2*filters, kernel_size = (1, 1, 1), kernel_regularizer=regularizers.l2(l2_), padding = \"same\", name='SR_Unit_'+str(filters)+'_conv_4')(X)\n",
    "    X = BatchNormalization(axis = 4, name='SR_Unit_'+str(filters)+'_bn_4')(X)\n",
    "\n",
    "    X_shortcut = Conv3D(filters = 2*filters, kernel_size = (3, 3, 3), padding = 'same', kernel_regularizer=regularizers.l2(l2_), name='SR_Unit_'+str(filters)+'_conv_5')(X_shortcut)\n",
    "    X_shortcut = BatchNormalization(axis = 4, name='SR_Unit_'+str(filters)+'_bn_5')(X_shortcut)\n",
    "\n",
    "    X = Add()([X, X_shortcut])\n",
    "    X = Activation('relu', name='SR_Unit_'+str(filters)+'_activation_5')(X)\n",
    "    \n",
    "    return X\n",
    "\n",
    "def feature_extraction(Sample):\n",
    "    X = Sample\n",
    "    \n",
    "    X = Conv3D(32, (8, 3, 3), kernel_regularizer=regularizers.l2(0.001), strides=(2,2,2), name='conv_0')(X)\n",
    "    X = BatchNormalization(axis=4, name='bn_conv_0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    X = MaxPooling3D((1, 2, 2), strides=None, name='MaxPooling_0')(X)\n",
    "    \n",
    "    # Stage 2\n",
    "    F1 = 16\n",
    "    X = SR_Unit(X, filters=F1)\n",
    "    \n",
    "    F2 = 32\n",
    "    X = SR_Unit(X, filters=F2)\n",
    "\n",
    "#     F3 = 64\n",
    "#     X = SR_Unit(X, filters=F3)\n",
    "\n",
    "#     F4 = 128\n",
    "#     X = SR_Unit(X, filters=F4)\n",
    "\n",
    "    return X\n",
    "\n",
    "def model(input_shape=(103, 50, 50, 1), classes=9):\n",
    "    X_input = Input(input_shape)\n",
    "    \n",
    "    X = feature_extraction(X_input)\n",
    "    \n",
    "    X = GlobalMaxPooling3D()(X)\n",
    "    X = Dense(256, input_dim=X.shape, activation='relu', name='fc_256', kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    X = Dense(classes, input_dim=X.shape, activation='softmax', name='fc' + str(classes), kernel_initializer = glorot_uniform(seed=0))(X)\n",
    "    \n",
    "    model = Model(inputs = X_input, outputs = X, name=\"3D-SRNet\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pavia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(610, 340, 103) (610, 340)\n",
      "(103, 610, 340) (610, 340)\n"
     ]
    }
   ],
   "source": [
    "uPavia = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\pavia\\\\PaviaU.mat')\n",
    "gt_uPavia = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\pavia\\\\PaviaU_gt.mat')\n",
    "data_PV = uPavia['paviaU']\n",
    "gt_PV = gt_uPavia['paviaU_gt']\n",
    "print(data_PV.shape, gt_PV.shape)\n",
    "data_PV = np.moveaxis(data_PV, 2, 0)\n",
    "print(data_PV.shape, gt_PV.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4 5 6 7 8 9] [164624   6631  18649   2099   3064   1345   5029   1330   3682    947]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,counts = np.unique(gt_PV, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples per class: [475, 881, 131, 347, 104, 312, 95, 343, 104], Total number of samples is 2792.\n",
      "\n",
      "unique classes in Ytest: [1 2 3 4 5 6 7 8 9], Total number of samples in Ytest is 562.\n",
      "number of samples per class in Ytest: [ 95 177  27  70  21  63  19  69  21]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest, class_len, counts = prepare_data_for_training(range_of_class = range_of_class, Cube_size = 25, Data = data_PV , Gt = gt_PV, small_segmented_1 = [], small_seg_gt_1 = [], percentage = 80, overlap_ratio = 0.8, ch = 103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2230, 103, 24, 24, 1), (562, 103, 24, 24, 1), (2230, 9), (562, 9))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\de991521\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 103, 24, 24,  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv_0 (Conv3D)                 (None, 48, 11, 11, 3 2336        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv_0 (BatchNormalization)  (None, 48, 11, 11, 3 128         conv_0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 48, 11, 11, 3 0           bn_conv_0[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "MaxPooling_0 (MaxPooling3D)     (None, 48, 5, 5, 32) 0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_1 (Conv3D)      (None, 48, 5, 5, 16) 528         MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_1 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_1 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_2 (Conv3D)      (None, 48, 5, 5, 16) 2320        SR_Unit_16_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_2 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_2 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_3 (Conv3D)      (None, 48, 5, 5, 16) 784         SR_Unit_16_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_3 (BatchNormaliza (None, 48, 5, 5, 16) 64          SR_Unit_16_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_3 (Activa (None, 48, 5, 5, 16) 0           SR_Unit_16_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_4 (Conv3D)      (None, 48, 5, 5, 32) 544         SR_Unit_16_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_conv_5 (Conv3D)      (None, 48, 5, 5, 32) 27680       MaxPooling_0[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_4 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_bn_5 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_16_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 48, 5, 5, 32) 0           SR_Unit_16_bn_4[0][0]            \n",
      "                                                                 SR_Unit_16_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_16_activation_5 (Activa (None, 48, 5, 5, 32) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_1 (Conv3D)      (None, 48, 5, 5, 32) 1056        SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_1 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_1[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_1 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_2 (Conv3D)      (None, 48, 5, 5, 32) 9248        SR_Unit_32_activation_1[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_2 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_2[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_2 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_3 (Conv3D)      (None, 48, 5, 5, 32) 3104        SR_Unit_32_activation_2[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_3 (BatchNormaliza (None, 48, 5, 5, 32) 128         SR_Unit_32_conv_3[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_3 (Activa (None, 48, 5, 5, 32) 0           SR_Unit_32_bn_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_4 (Conv3D)      (None, 48, 5, 5, 64) 2112        SR_Unit_32_activation_3[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_conv_5 (Conv3D)      (None, 48, 5, 5, 64) 55360       SR_Unit_16_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_4 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_4[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_bn_5 (BatchNormaliza (None, 48, 5, 5, 64) 256         SR_Unit_32_conv_5[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 48, 5, 5, 64) 0           SR_Unit_32_bn_4[0][0]            \n",
      "                                                                 SR_Unit_32_bn_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "SR_Unit_32_activation_5 (Activa (None, 48, 5, 5, 64) 0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling3d_1 (GlobalM (None, 64)           0           SR_Unit_32_activation_5[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "fc_256 (Dense)                  (None, 256)          16640       global_max_pooling3d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "fc9 (Dense)                     (None, 9)            2313        fc_256[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 125,497\n",
      "Trainable params: 124,761\n",
      "Non-trainable params: 736\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_1 = model(input_shape = Xtrain[0].shape, classes = len(range_of_class))\n",
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2230 samples, validate on 562 samples\n",
      "Epoch 1/50\n",
      "2230/2230 [==============================] - 133s 60ms/step - loss: 11.2540 - categorical_accuracy: 0.3076 - val_loss: 11.4099 - val_categorical_accuracy: 0.3149\n",
      "Epoch 2/50\n",
      "2230/2230 [==============================] - 127s 57ms/step - loss: 11.3929 - categorical_accuracy: 0.3157 - val_loss: 11.3998 - val_categorical_accuracy: 0.3149\n",
      "Epoch 3/50\n",
      "2230/2230 [==============================] - 141s 63ms/step - loss: 11.3829 - categorical_accuracy: 0.3157 - val_loss: 11.3899 - val_categorical_accuracy: 0.3149\n",
      "Epoch 4/50\n",
      "2230/2230 [==============================] - 138s 62ms/step - loss: 11.3731 - categorical_accuracy: 0.3157 - val_loss: 11.3803 - val_categorical_accuracy: 0.3149\n",
      "Epoch 5/50\n",
      "2230/2230 [==============================] - 135s 60ms/step - loss: 11.3636 - categorical_accuracy: 0.3157 - val_loss: 11.3710 - val_categorical_accuracy: 0.3149\n",
      "Epoch 6/50\n",
      "2230/2230 [==============================] - 134s 60ms/step - loss: 11.3544 - categorical_accuracy: 0.3157 - val_loss: 11.3619 - val_categorical_accuracy: 0.3149\n",
      "Epoch 7/50\n",
      "2230/2230 [==============================] - 135s 61ms/step - loss: 11.3455 - categorical_accuracy: 0.3157 - val_loss: 11.3531 - val_categorical_accuracy: 0.3149\n",
      "Epoch 8/50\n",
      "2230/2230 [==============================] - 150s 67ms/step - loss: 11.3368 - categorical_accuracy: 0.3157 - val_loss: 11.3445 - val_categorical_accuracy: 0.3149\n",
      "Epoch 9/50\n",
      "1056/2230 [=============>................] - ETA: 1:16 - loss: 11.3820 - categorical_accuracy: 0.3125"
     ]
    }
   ],
   "source": [
    "model_1.compile(optimizer= keras.optimizers.SGD(lr=0.01, decay=1e-5, momentum=0.9, nesterov=True), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_1.fit(Xtrain, Ytrain, epochs = 50, batch_size = 32, validation_data=(Xtest,Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_1.evaluate(Xtest, Ytest)\n",
    "# print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict(Xtest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(y_pred, axis=1))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.layers[0:36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(input=model_1.layers[0].input, output=model_1.layers[35].output)\n",
    "model_new.save(\"model_pavia_overlap_80.h5\")\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Salinas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uSalinas = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Salinas\\\\Salinas_corrected.mat')\n",
    "gt_uSalinas = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Salinas\\\\Salinas_gt.mat')\n",
    "data_SA = uSalinas['salinas_corrected']\n",
    "gt_SA = gt_uSalinas['salinas_gt']\n",
    "print(data_SA.shape, gt_SA.shape)\n",
    "data_SA = np.moveaxis(data_SA, 2, 0)\n",
    "print(data_SA.shape, gt_SA.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,counts = np.unique(gt_SA, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest, class_len, counts = prepare_data_for_training(range_of_class = range_of_class, Cube_size = 25, Data = data_SA , Gt = gt_SA, small_segmented_1 = [], small_seg_gt_1 = [], percentage = 80, overlap_ratio = 0.8, ch=103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model(input_shape = Xtrain[0].shape, classes = len(range_of_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer= keras.optimizers.SGD(lr=0.001, decay=1e-5, momentum=0.9), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_1.fit(Xtrain, Ytrain, epochs = 45, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.layers[0:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(input=model_1.layers[0].input, output=model_1.layers[35].output)\n",
    "model_new.save(\"model_salinas.h5\")\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_1.evaluate(Xtest, Ytest)\n",
    "# print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict(Xtest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(y_pred, axis=1))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Indian Pines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uIndian_pines = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Indian Pines\\\\Indian_pines_corrected.mat')\n",
    "gt_uIndian_pines = sio.loadmat('C:\\\\Users\\\\de991521\\\\Desktop\\\\EE_297_PROJECT\\\\Indian Pines\\\\Indian_pines_gt.mat')\n",
    "data_IN = uIndian_pines['indian_pines_corrected']\n",
    "gt_IN = gt_uIndian_pines['indian_pines_gt']\n",
    "print(data_IN.shape, gt_IN.shape)\n",
    "data_IN = np.moveaxis(data_IN, 2, 0)\n",
    "print(data_IN.shape, gt_IN.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values,counts = np.unique(gt_IN, return_counts=True)\n",
    "print(values,counts)\n",
    "range_of_class = list(values)\n",
    "if 0 in range_of_class:\n",
    "    range_of_class.pop(0)\n",
    "range_of_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest, class_len, counts = prepare_data_for_training(range_of_class = range_of_class, Cube_size = 10, Data = data_IN , Gt = gt_IN, small_segmented_1 = [], small_seg_gt_1 = [], percentage = 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain.shape, Xtest.shape, Ytrain.shape, Ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1 = model(input_shape = Xtrain[0].shape, classes = len(range_of_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.compile(optimizer= keras.optimizers.SGD(lr=0.01, decay=1e-5, momentum=0.9), loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n",
    "model_1.fit(Xtrain,model_1.layers[0:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1.layers[0:35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Model(input=model_1.layers[0].input, output=model_1.layers[35].output)\n",
    "model_new.save(\"model_indian.h5\")\n",
    "model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model_1.evaluate(Xtest, Ytest)\n",
    "# print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model_1.predict(Xtest, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = sklearn.metrics.confusion_matrix(np.argmax(Ytest, axis=1), np.argmax(y_pred, axis=1))\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
